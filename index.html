<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover" />
  <title>Multi‚ÄëPerson Skeleton ‚Äî MoveNet (TF.js)</title>
  <meta name="theme-color" content="#0b0b0c">
  <style>
    :root{
      --bg:#0b0b0c;          /* page background */
      --panel:#111214;       /* top bar background */
      --ink:#e6e6e6;         /* primary text */
      --muted:#9aa0a6;       /* secondary text */
      --accent:#4c9aff;      /* buttons/focus */
      --danger:#ff5c5c;      /* error */
      --ok:#2ecc71;          /* running */
      --warn:#ffc54d;        /* loading */
    }
    *{box-sizing:border-box}
    html,body{height:100%}
    body{
      margin:0;
      background:var(--bg);
      color:var(--ink);
      font:14px/1.45 system-ui, -apple-system, Segoe UI, Roboto, Inter, Arial, sans-serif;
      overscroll-behavior:none;
    }

    /* Layout */
    .app{
      position:fixed; inset:0;
      display:grid; grid-template-rows:auto 1fr auto;
    }
    .topbar{
      display:flex; align-items:center; gap:12px;
      padding:10px 12px; background:var(--panel);
      border-bottom:1px solid #1a1c1f;
    }
    .title{font-weight:600; letter-spacing:.2px}
    .spacer{flex:1}
    .controls{display:flex; align-items:center; gap:12px; flex-wrap:wrap}
    .btn{
      padding:8px 12px; border-radius:10px; border:1px solid #2a2d32;
      background:#15171a; color:var(--ink); cursor:pointer;
    }
    .btn:hover{background:#1a1d21}
    .btn:active{transform:translateY(1px)}
    .btn[aria-pressed="true"]{outline:2px solid var(--accent)}
    .toggle{display:flex; align-items:center; gap:6px; user-select:none}
    .status{display:flex; align-items:center; gap:8px; color:var(--muted)}
    .dot{width:10px; height:10px; border-radius:50%}

    .stage{position:relative; overflow:hidden; background:#000;}
    canvas{position:absolute; inset:0; width:100%; height:100%; display:block}
    video{display:none}

    .notice{
      color:var(--muted); padding:8px 12px; background:#0f1012; border-top:1px solid #1a1c1f;
      display:flex; justify-content:space-between; align-items:center; gap:12px; flex-wrap:wrap;
    }
    .error{color:#fff; background:rgba(255,92,92,.1); border:1px solid rgba(255,92,92,.35);
           padding:8px 10px; border-radius:8px}
    .link{color:var(--accent); text-decoration:none}
    .link:hover{text-decoration:underline}
  </style>
</head>
<body>
  <div class="app">
    <!-- Top Bar / Controls -->
    <div class="topbar">
      <div class="status">
        <span class="dot" id="status-dot" style="background:var(--warn)"></span>
        <span id="status-text">Loading model‚Ä¶</span>
      </div>
      <div class="spacer"></div>
      <div class="controls">
        <button id="startStop" class="btn" type="button">Start</button>
        <label class="toggle"><input id="toggleKeypoints" type="checkbox" checked> Show keypoints</label>
        <label class="toggle"><input id="toggleBones" type="checkbox" checked> Show bones</label>
        <label class="toggle"><input id="toggleFps" type="checkbox" checked> Show FPS</label>
      </div>
    </div>

    <!-- Stage -->
    <div class="stage" id="stage">
      <canvas id="canvas"></canvas>
      <video id="video" playsinline></video>
    </div>

    <!-- Footer notice & errors -->
    <div class="notice">
      <div>üõ°Ô∏è Camera runs locally in your browser; no data is sent.</div>
      <div id="errorBox" class="error" style="display:none"></div>
    </div>
  </div>

  <!-- TensorFlow.js & Pose Detection (via CDN) -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.20.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.20.0/dist/tf-backend-webgl.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm@4.20.0/dist/tf-backend-wasm.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@3.8.0/dist/pose-detection.min.js"></script>

  <script>
  (function(){
    // DOM refs
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const video = document.getElementById('video');
    const startStopBtn = document.getElementById('startStop');
    const statusDot = document.getElementById('status-dot');
    const statusText = document.getElementById('status-text');
    const errorBox = document.getElementById('errorBox');

    const showKeypointsEl = document.getElementById('toggleKeypoints');
    const showBonesEl = document.getElementById('toggleBones');
    const showFpsEl = document.getElementById('toggleFps');

    // State
    let detector = null;
    let running = false;
    let rafId = null;
    let stream = null;

    // FPS tracking
    const fpsWindow = [];
    let lastFrameTs = 0;

    // Colors per person index
    const COLORS = [
      '#4c9aff', '#ff5c93', '#7bed8b', '#ffd166', '#9b6bff', '#5cd4ff'
    ];

    // Skeleton edges (COCO/MoveNet keypoint names)
    const EDGES = [
      ['leftShoulder','rightShoulder'],
      ['leftShoulder','leftElbow'], ['leftElbow','leftWrist'],
      ['rightShoulder','rightElbow'], ['rightElbow','rightWrist'],
      ['leftShoulder','leftHip'], ['rightShoulder','rightHip'],
      ['leftHip','rightHip'],
      ['leftHip','leftKnee'], ['leftKnee','leftAnkle'],
      ['rightHip','rightKnee'], ['rightKnee','rightAnkle'],
      ['nose','leftEye'], ['leftEye','leftEar'],
      ['nose','rightEye'], ['rightEye','rightEar']
    ];

    // Resize canvas to fill window
    function resizeCanvas(){
      const dpr = Math.min(window.devicePixelRatio || 1, 2);
      const {clientWidth:w, clientHeight:h} = document.getElementById('stage');
      canvas.width = Math.floor(w * dpr);
      canvas.height = Math.floor(h * dpr);
      canvas.style.width = w + 'px';
      canvas.style.height = h + 'px';
      ctx.setTransform(dpr, 0, 0, dpr, 0, 0); // reset scale for crisp lines
    }
    window.addEventListener('resize', resizeCanvas);

    // UI helpers
    function setStatus(colorVar, text){
      statusDot.style.background = getComputedStyle(document.documentElement).getPropertyValue(colorVar).trim() || colorVar;
      statusText.textContent = text;
    }
    function showError(msg){
      errorBox.style.display = 'block';
      errorBox.textContent = msg;
      setStatus('--danger', 'Error');
    }
    function clearError(){
      errorBox.style.display = 'none';
      errorBox.textContent = '';
    }

    // Initialize TF backend and model
    async function loadModel(){
      try{
        // Prefer WebGL, but fall back to WASM on browsers that block WebGL (iOS/Safari Low Power, etc.)
        let backend = 'webgl';
        try{
          await tf.setBackend('webgl');
          await tf.ready();
        }catch(e){
          backend = 'wasm';
        }
        if(backend === 'wasm'){
          // Point WASM to its CDN path before selecting the backend
          // eslint-disable-next-line no-undef
          tf.wasm?.setWasmPaths?.('https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm@4.20.0/dist/');
          await tf.setBackend('wasm');
          await tf.ready();
        }

        const model = poseDetection.SupportedModels.MoveNet;
        detector = await poseDetection.createDetector(model, {
          modelType: poseDetection.movenet.modelType.MULTIPOSE_LIGHTNING,
          enableSmoothing: true,
          minPoseScore: 0.15
        });
        setStatus('--warn',`Model loaded (${tf.getBackend()}) ‚Äî ready to start`);
      }catch(err){
        console.error(err);
        showError('Failed to load TensorFlow.js or model. Try a modern browser over HTTPS.');
      }
    });
        setStatus('--warn','Model loaded ‚Äî ready to start');
      }catch(err){
        console.error(err);
        showError('Failed to load TensorFlow.js or model. Try a modern browser over HTTPS.');
      }
    }

    // Start camera (prefer 720p for speed)
    async function startCamera(){
      try{
        stream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: 'user', // selfie
            width: { ideal: 1280 },
            height: { ideal: 720 },
            frameRate: { ideal: 60, max: 60 }
          },
          audio: false
        });
        video.srcObject = stream;
        await video.play();
      }catch(err){
        console.error(err);
        if(err.name === 'NotAllowedError'){
          showError('Camera permission denied. Please allow access and reload.');
        }else if(err.name === 'NotFoundError'){
          showError('No camera found on this device.');
        }else{
          showError('Unable to start camera: ' + err.message);
        }
        throw err; // rethrow to stop start flow
      }
    }

    // Stop camera
    function stopCamera(){
      if(stream){
        for(const track of stream.getTracks()) track.stop();
        stream = null;
      }
      video.srcObject = null;
    }

    function drawMirroredVideo(){
      const vw = video.videoWidth || 0, vh = video.videoHeight || 0;
      if(!vw || !vh) return;

      const cw = canvas.width / (window.devicePixelRatio ? Math.min(window.devicePixelRatio,2) : 1);
      const ch = canvas.height / (window.devicePixelRatio ? Math.min(window.devicePixelRatio,2) : 1);
      // Letterbox to cover canvas while preserving aspect ratio
      const vidAspect = vw / vh;
      const canAspect = cw / ch;
      let dw, dh;
      if(vidAspect > canAspect){ dw = cw; dh = cw / vidAspect; }
      else { dh = ch; dw = ch * vidAspect; }
      const dx = (cw - dw) / 2;
      const dy = (ch - dh) / 2;

      // Mirror draw: flip X, then draw video
      ctx.save();
      ctx.translate(cw, 0);
      ctx.scale(-1, 1);
      ctx.drawImage(video, dx, dy, dw, dh);
      ctx.restore();

      return {dx, dy, dw, dh, cw, ch, scaleX: dw / vw, scaleY: dh / vh};
    }

    function drawKeypoint(x, y, color){
      const r = 3.5;
      ctx.beginPath();
      ctx.arc(x, y, r, 0, Math.PI*2);
      ctx.fillStyle = color;
      ctx.fill();
    }

    function drawLine(x1,y1,x2,y2,color){
      ctx.beginPath();
      ctx.moveTo(x1,y1);
      ctx.lineTo(x2,y2);
      ctx.lineWidth = 2.5;
      ctx.strokeStyle = color;
      ctx.stroke();
    }

    function nameToPoint(map, name){
      return map.get(name) || null;
    }

    function drawSkeletonForPerson(person, view, color, showPoints, showEdges){
      // person.keypoints has {x,y,name,score}
      const kpMap = new Map();
      for(const kp of person.keypoints){
        if(kp.score == null || kp.score < 0.3) continue;
        // Mirror X for overlay to align with mirrored video
        const x = view.cw - (view.dx + kp.x * view.scaleX);
        const y = view.dy + kp.y * view.scaleY;
        kpMap.set(kp.name, {x,y});
        if(showPoints) drawKeypoint(x, y, color);
      }
      if(!showEdges) return;
      for(const [a,b] of EDGES){
        const pa = nameToPoint(kpMap, a);
        const pb = nameToPoint(kpMap, b);
        if(pa && pb) drawLine(pa.x, pa.y, pb.x, pb.y, color);
      }
    }

    function drawFps(fps){
      const txt = fps.toFixed(1) + ' FPS';
      ctx.save();
      ctx.font = '12px system-ui, -apple-system, Segoe UI, Roboto, Inter, Arial, sans-serif';
      ctx.fillStyle = 'rgba(0,0,0,0.5)';
      ctx.fillRect(8, 8, ctx.measureText(txt).width + 10, 20);
      ctx.fillStyle = '#fff';
      ctx.fillText(txt, 13, 23);
      ctx.restore();
    }

    async function detectLoop(){
      if(!running) return;
      resizeCanvas();
      ctx.clearRect(0,0,canvas.width,canvas.height);

      const view = drawMirroredVideo();
      if(!view){ rafId = requestAnimationFrame(detectLoop); return; }

      if(!detector){
        // If detector isn't ready, try to (re)load once more and skip this frame
        try{ await loadModel(); }catch(e){}
        rafId = requestAnimationFrame(detectLoop);
        return;
      }

      // Estimate poses (max 6 people). Don't flip here; we handle mirroring in drawing.
      let poses = [];
      try{
        poses = await detector.estimatePoses(video, { maxPoses: 6, flipHorizontal: false });
      }catch(err){
        console.error(err);
        showError('Pose detection error: ' + err.message);
      }

      // Draw skeletons
      for(let i=0;i<poses.length;i++){
        const color = COLORS[i % COLORS.length];
        drawSkeletonForPerson(poses[i], view, color, showKeypointsEl.checked, showBonesEl.checked);
      }

      // FPS calc
      const now = performance.now();
      if(lastFrameTs){
        const dt = now - lastFrameTs; // ms
        const fps = 1000 / dt;
        fpsWindow.push(fps);
        if(fpsWindow.length > 30) fpsWindow.shift();
        const avg = fpsWindow.reduce((a,b)=>a+b,0) / fpsWindow.length;
        if(showFpsEl.checked) drawFps(avg);
      }
      lastFrameTs = now;

      rafId = requestAnimationFrame(detectLoop);
    }

      // Estimate poses (max 6 people). Don't flip here; we handle mirroring in drawing.
      let poses = [];
      try{
        poses = await detector.estimatePoses(video, { maxPoses: 6, flipHorizontal: false });
      }catch(err){
        console.error(err);
        showError('Pose detection error: ' + err.message);
      }

      // Draw skeletons
      for(let i=0;i<poses.length;i++){
        const color = COLORS[i % COLORS.length];
        drawSkeletonForPerson(poses[i], view, color, showKeypointsEl.checked, showBonesEl.checked);
      }

      // FPS calc
      const now = performance.now();
      if(lastFrameTs){
        const dt = now - lastFrameTs; // ms
        const fps = 1000 / dt;
        fpsWindow.push(fps);
        if(fpsWindow.length > 30) fpsWindow.shift();
        const avg = fpsWindow.reduce((a,b)=>a+b,0) / fpsWindow.length;
        if(showFpsEl.checked) drawFps(avg);
      }
      lastFrameTs = now;

      rafId = requestAnimationFrame(detectLoop);
    }

    async function start(){
      clearError();
      if(!detector){ await loadModel(); }
      await startCamera();
      running = true;
      startStopBtn.textContent = 'Stop';
      setStatus('--ok','Running');
      lastFrameTs = 0;
      fpsWindow.length = 0;
      cancelAnimationFrame(rafId);
      detectLoop();
    }

    function stop(){
      running = false;
      cancelAnimationFrame(rafId);
      stopCamera();
      startStopBtn.textContent = 'Start';
      setStatus('--warn','Paused');
    }

    // Button wiring
    startStopBtn.addEventListener('click', async ()=>{
      if(running) stop(); else {
        try{ await start(); }
        catch(e){ /* error already surfaced */ }
      }
    });

    // Initial startup: pre-load model; don't auto-start camera (user gesture preferred)
    (async function init(){
      resizeCanvas();
      if(!('mediaDevices' in navigator) || !('getUserMedia' in navigator.mediaDevices)){
        showError('This browser does not support camera access (getUserMedia).');
        setStatus('--danger','Unavailable');
        return;
      }
      setStatus('--warn','Loading model‚Ä¶');
      await loadModel();
      if(detector) setStatus('--warn','Model loaded ‚Äî press Start');
    })();

    // Page visibility: auto-pause on hidden
    document.addEventListener('visibilitychange', ()=>{
      if(document.hidden && running){ stop(); }
    });
  })();
  </script>
</body>
</html>
